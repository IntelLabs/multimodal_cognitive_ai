<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="LVLM Interpret">
  <meta property="og:title" content="LVLM Interpret"/>
  <meta property="og:description" content="LVLM Interpret: An Interpretability Tool for Large Vision-Language Models"/>
  <meta property="og:url" content="https://intellabs.github.io/multimodal_cognitive_ai/lvlm_interpret/"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="LVLM Interpret">
  <meta name="twitter:description" content="LVLM Interpret: An Interpretability Tool for Large Vision-Language Models">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/static/images/comparisons_interface.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="Vision-and-Language, Multimodal, Explainability, Interpretability">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>NeuroPrompts </title>
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üë®‚Äçüé®</text></svg>">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">-->

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">NeuroPrompts: An Adaptive Framework to Optimize Prompts for Text-to-Image Generation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=IV0Nu40AAAAJ&hl=en" target="_blank">Shao-Yen Tseng</a>,&nbsp;</span>
                <span class="author-block">
                  <a href="https://scholar.google.com/citations?user=Qbu4oKwAAAAJ&hl=en" target="_blank">Vasudev Lal</a>,&nbsp;</span>
                    <span class="author-block">
                      <a href="https://dblp.org/pid/327/6836.html" target="_blank">Gabriela Ben Melech Stan</a>,&nbsp;</span>
                      <span class="author-block">
                        <a href="https://scholar.google.co.il/citations?user=B7SmLVkAAAAJ&hl=en" target="_blank">Raanan Yehezkel Rohekar</a>,&nbsp;</span>
                        <span class="author-block">
                          <a href="https://scholar.google.co.il/citations?user=K7bXPLgAAAAJ&hl=en" target="_blank">Yaniv Gurwicz</a>,&nbsp;</span>
                          <span class="author-block">
                            <a href="https://scholar.google.com/citations?user=xcGKR8EAAAAJ&hl=en" target="_blank">Matthew Lyle Olson</a>,&nbsp;</span>
                            <span class="author-block">
                              <a href="https://scholar.google.com/citations?user=N-Qoq1gAAAAJ&hl=en" target="_blank">Anahita Bhiwandiwalla</a>,&nbsp;</span>
                              <span class="author-block">
                                <a href="https://www.semanticscholar.org/author/Estelle-Aflalo/1816753600" target="_blank">Estelle Aflalo</a>,&nbsp;</span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Intel Labs&nbsp;&nbsp;</span>
                  </div>

<!--                  &lt;!&ndash; Github link &ndash;&gt;-->
<!--                  <span class="link-block">-->
<!--                    <a href="https://github.com/YOUR REPO HERE" target="_blank"-->
<!--                    class="external-link button is-normal is-rounded is-dark">-->
<!--                    <span class="icon">-->
<!--                      <i class="fab fa-github"></i>-->
<!--                    </span>-->
<!--                    <span>Code</span>-->
<!--                  </a>-->
<!--                </span>-->

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/TODEFINE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                <!-- Demo Link -->
                <span class="link-block">
                  <a href="http://3.131.193.145:7860/" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <p style="font-size:20px">&#x1F917;</p>
                  </span>
                  <span>Demo</span>
                </a>
              </span>

              <span class="link-block">
                  <a href="https://github.com/IntelLabs/multimodal_cognitive_ai/tree/main/Demos/TODEFINE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                </a>
              </span>

              <span class="link-block">
                  <a href="https://youtu.be/TODEFINE" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="fas fa-video"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>   

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>
	
<section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <h4 class="subtitle has-text-centered">
          LVLM-Intrepret is an interpretability tool that allows to visualize the inner workings of Large Vision-Language models.
        </h4>
      </div>
    </div>
</section>

	
<section class="section"  style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">The interface of the LVLM-interpret application</h2>
          <div class="content has-text-justified">
             <img id="comparisons_interface_fig" src="static/images/interface_basic.png" alt="Paris"> 
  
          </div>
        </div>
      </div>
        
    </div>
</section>
	
<section class="section"  style="background-color:#efeff081">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-six-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              ABSTRACT HERE
           </p>
  
          </div>
        </div>
      </div>
        
    </div>
</section>


<section class="section" style="background-color: #efeff081">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Example of interaction performed with LVLM Interpret</h2>
        <div class="content has-text-justified">
          <div style="display: flex; justify-content: center;">
            <img id="examples_fig" src="static/images/interface_draw.png" alt="Paris" style="max-width: 100%; height: auto;">
          </div>
        </div>
      </div>
    </div>
  </div>
</section>




<!-- Paper poster -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Paper</h2>
      <iframe  src="static/pdfs/Prompt_Engineering_4.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section>
<!--End paper poster -->

<section class="section" style="background-color: #efeff081">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <h2 class="title is-3">Screencast video demo</h2>
        <div class="content has-text-justified">
          <div style="display: flex; justify-content: center;">
            <iframe width="560" height="315" src="https://www.youtube.com/embed/Cmca_RWYn2g" title="YouTube video player"
		    frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

	


<!--BibTex citation -->
<section class="hero is-small is-light">
  <div class="hero-body">
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX TODO!</h2>
      <pre><code>@inproceedings{howard-etal-2022-neurocounterfactuals,
    title = "{N}euro{C}ounterfactuals: Beyond Minimal-Edit Counterfactuals for Richer Data Augmentation",
    author = "Howard, Phillip  and
      Singer, Gadi  and
      Lal, Vasudev  and
      Choi, Yejin  and
      Swayamdipta, Swabha",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.371",
    doi = "10.18653/v1/2022.findings-emnlp.371",
    pages = "5056--5072",
    abstract = "While counterfactual data augmentation offers a promising step towards robust generalization in natural language processing, producing a set of counterfactuals that offer valuable inductive bias for models remains a challenge. Most existing approaches for producing counterfactuals, manual or automated, rely on small perturbations via minimal edits, resulting in simplistic changes. We introduce NeuroCounterfactuals, designed as loose counterfactuals, allowing for larger edits which result in naturalistic generations containing linguistic diversity, while still bearing similarity to the original document. Our novel generative approach bridges the benefits of constrained decoding, with those of language model adaptation for sentiment steering. Training data augmentation with our generations results in both in-domain and out-of-domain improvements for sentiment classification, outperforming even manually curated counterfactuals, under select settings. We further present detailed analyses to show the advantages of NeuroCounterfactuals over approaches involving simple, minimal edits.",
}</code></pre>
    </div>
</section>
    </div>
</section>
<!--End BibTex citation -->

  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p style="color:gray;font-size:9.9px;">
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>, is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
            <a href="https://www.flaticon.com/free-icons/magic" title="magic icons">Magic icons created by Freepik - Flaticon</a>
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->
  </body>
  </html>
